
# See LICENSE for license details.

# This file is automatically generated. Do not edit.

#*****************************************************************************
# isa/rv64uv/vsll_vi_LMUL1SEW8VL16.S
#-----------------------------------------------------------------------------
#
# Test vsll.vi instructions.
# With LMUL=1, SEW=8, VL=16
#

#include "riscv_test.h"
#include "test_macros.h"

RVTEST_RV64UV

RVTEST_CODE_BEGIN

  la a1, tdat
  la a3, sres
  lbu a4, 0(a1)
  li a5, 1
  slli a5, a5, 61
  srli a5, a5, 61
  sll a5, a4, a5
  sb a5, 0(a3)
  lbu a4, 1(a1)
  li a5, 1
  slli a5, a5, 61
  srli a5, a5, 61
  sll a5, a4, a5
  sb a5, 1(a3)
  lbu a4, 2(a1)
  li a5, 1
  slli a5, a5, 61
  srli a5, a5, 61
  sll a5, a4, a5
  sb a5, 2(a3)
  lbu a4, 3(a1)
  li a5, 1
  slli a5, a5, 61
  srli a5, a5, 61
  sll a5, a4, a5
  sb a5, 3(a3)
  lbu a4, 4(a1)
  li a5, 1
  slli a5, a5, 61
  srli a5, a5, 61
  sll a5, a4, a5
  sb a5, 4(a3)
  lbu a4, 5(a1)
  li a5, 1
  slli a5, a5, 61
  srli a5, a5, 61
  sll a5, a4, a5
  sb a5, 5(a3)
  lbu a4, 6(a1)
  li a5, 1
  slli a5, a5, 61
  srli a5, a5, 61
  sll a5, a4, a5
  sb a5, 6(a3)
  lbu a4, 7(a1)
  li a5, 1
  slli a5, a5, 61
  srli a5, a5, 61
  sll a5, a4, a5
  sb a5, 7(a3)
  lbu a4, 8(a1)
  li a5, 1
  slli a5, a5, 61
  srli a5, a5, 61
  sll a5, a4, a5
  sb a5, 8(a3)
  lbu a4, 9(a1)
  li a5, 1
  slli a5, a5, 61
  srli a5, a5, 61
  sll a5, a4, a5
  sb a5, 9(a3)
  lbu a4, 10(a1)
  li a5, 1
  slli a5, a5, 61
  srli a5, a5, 61
  sll a5, a4, a5
  sb a5, 10(a3)
  lbu a4, 11(a1)
  li a5, 1
  slli a5, a5, 61
  srli a5, a5, 61
  sll a5, a4, a5
  sb a5, 11(a3)
  lbu a4, 12(a1)
  li a5, 1
  slli a5, a5, 61
  srli a5, a5, 61
  sll a5, a4, a5
  sb a5, 12(a3)
  lbu a4, 13(a1)
  li a5, 1
  slli a5, a5, 61
  srli a5, a5, 61
  sll a5, a4, a5
  sb a5, 13(a3)
  lbu a4, 14(a1)
  li a5, 1
  slli a5, a5, 61
  srli a5, a5, 61
  sll a5, a4, a5
  sb a5, 14(a3)
  lbu a4, 15(a1)
  li a5, 1
  slli a5, a5, 61
  srli a5, a5, 61
  sll a5, a4, a5
  sb a5, 15(a3)


  li t0, -1
  vsetvli t1, t0, e8,m1,ta,ma
  la a2, tdat
  vle8.v v2, (a2)
  vle8.v v1, (a2)

  
  li t0, 16
  vsetvli t1, t0, e8,m1,ta,ma
  vsll.vi v1, v2, 1

  li t0, -1
  vsetvli t1, t0, e8,m1,ta,ma
  la a1, res
  vse8.v v1, (a1)
  la a2, sres

  TEST_CASE_REG(3, t0, t1, ld t0, 0(a1); ld t1, 0(a2); addi a1, a1, 8; addi a2, a2, 8)
  TEST_CASE_REG(4, t0, t1, ld t0, 0(a1); ld t1, 0(a2); addi a1, a1, 8; addi a2, a2, 8)

  li t0, -1
  vsetvli t1, t0, e8,m1,ta,ma
  la a2, tdat
  vle8.v v2, (a2)
  vle8.v v1, (a2)

  
  li t0, -1
  vsetvli t1, t0, e8,m1,ta,ma
  la a3, mask
  vle8.v v0, (a3)

  li t0, 16
  vsetvli t1, t0, e8,m1,ta,ma
  vsll.vi v1, v2, 1, v0.t

  li t0, -1
  vsetvli t1, t0, e8,m1,ta,ma
  la a1, res
  vse8.v v1, (a1)
  la a2, sres

  TEST_CASE_REG(5, t0, t1, lbu t0, 0(a1); lbu t1, 0(a2); addi a1, a1, 1; addi a2, a2, 1)
  addi a1, a1, 1; addi a2, a2, 1;
  TEST_CASE_REG(6, t0, t1, lbu t0, 0(a1); lbu t1, 0(a2); addi a1, a1, 1; addi a2, a2, 1)
  addi a1, a1, 1; addi a2, a2, 1;
  TEST_CASE_REG(7, t0, t1, lbu t0, 0(a1); lbu t1, 0(a2); addi a1, a1, 1; addi a2, a2, 1)
  addi a1, a1, 1; addi a2, a2, 1;
  TEST_CASE_REG(8, t0, t1, lbu t0, 0(a1); lbu t1, 0(a2); addi a1, a1, 1; addi a2, a2, 1)
  addi a1, a1, 1; addi a2, a2, 1;
  TEST_CASE_REG(9, t0, t1, lbu t0, 0(a1); lbu t1, 0(a2); addi a1, a1, 1; addi a2, a2, 1)
  addi a1, a1, 1; addi a2, a2, 1;
  TEST_CASE_REG(10, t0, t1, lbu t0, 0(a1); lbu t1, 0(a2); addi a1, a1, 1; addi a2, a2, 1)
  addi a1, a1, 1; addi a2, a2, 1;
  TEST_CASE_REG(11, t0, t1, lbu t0, 0(a1); lbu t1, 0(a2); addi a1, a1, 1; addi a2, a2, 1)
  addi a1, a1, 1; addi a2, a2, 1;
  TEST_CASE_REG(12, t0, t1, lbu t0, 0(a1); lbu t1, 0(a2); addi a1, a1, 1; addi a2, a2, 1)
  addi a1, a1, 1; addi a2, a2, 1;

  li t0, -1
  vsetvli t1, t0, e8,m1,ta,ma
  la a2, tdat
  vle8.v v2, (a2)
  vle8.v v1, (a2)

  
  li t0, 16
  vsetvli t1, t0, e8,m1,tu,ma
  vsll.vi v1, v2, 1

  li t0, -1
  vsetvli t1, t0, e8,m1,ta,ma
  la a1, res
  vse8.v v1, (a1)
  la a2, sres

  TEST_CASE_REG(13, t0, t1, ld t0, 0(a1); ld t1, 0(a2); addi a1, a1, 8; addi a2, a2, 8)
  TEST_CASE_REG(14, t0, t1, ld t0, 0(a1); ld t1, 0(a2); addi a1, a1, 8; addi a2, a2, 8)

  li t0, -1
  vsetvli t1, t0, e8,m1,ta,ma
  la a2, tdat
  vle8.v v2, (a2)
  vle8.v v1, (a2)

  
  li t0, -1
  vsetvli t1, t0, e8,m1,ta,ma
  la a3, mask
  vle8.v v0, (a3)

  li t0, 16
  vsetvli t1, t0, e8,m1,ta,ma
  vsll.vi v1, v2, 1, v0.t

  li t0, -1
  vsetvli t1, t0, e8,m1,ta,ma
  la a1, res
  vse8.v v1, (a1)
  la a2, sres

  TEST_CASE_REG(15, t0, t1, lbu t0, 0(a1); lbu t1, 0(a2); addi a1, a1, 1; addi a2, a2, 1)
  TEST_CASE(16, t0, 0xef, lbu t0, 0(a1); addi a1, a1, 1; addi a2, a2, 1)
  TEST_CASE_REG(17, t0, t1, lbu t0, 0(a1); lbu t1, 0(a2); addi a1, a1, 1; addi a2, a2, 1)
  TEST_CASE(18, t0, 0xff, lbu t0, 0(a1); addi a1, a1, 1; addi a2, a2, 1)
  TEST_CASE_REG(19, t0, t1, lbu t0, 0(a1); lbu t1, 0(a2); addi a1, a1, 1; addi a2, a2, 1)
  TEST_CASE(20, t0, 0x3, lbu t0, 0(a1); addi a1, a1, 1; addi a2, a2, 1)
  TEST_CASE_REG(21, t0, t1, lbu t0, 0(a1); lbu t1, 0(a2); addi a1, a1, 1; addi a2, a2, 1)
  TEST_CASE(22, t0, 0x0, lbu t0, 0(a1); addi a1, a1, 1; addi a2, a2, 1)
  TEST_CASE_REG(23, t0, t1, lbu t0, 0(a1); lbu t1, 0(a2); addi a1, a1, 1; addi a2, a2, 1)
  TEST_CASE(24, t0, 0x1, lbu t0, 0(a1); addi a1, a1, 1; addi a2, a2, 1)
  TEST_CASE_REG(25, t0, t1, lbu t0, 0(a1); lbu t1, 0(a2); addi a1, a1, 1; addi a2, a2, 1)
  TEST_CASE(26, t0, 0x1, lbu t0, 0(a1); addi a1, a1, 1; addi a2, a2, 1)
  TEST_CASE_REG(27, t0, t1, lbu t0, 0(a1); lbu t1, 0(a2); addi a1, a1, 1; addi a2, a2, 1)
  TEST_CASE(28, t0, 0x7, lbu t0, 0(a1); addi a1, a1, 1; addi a2, a2, 1)
  TEST_CASE_REG(29, t0, t1, lbu t0, 0(a1); lbu t1, 0(a2); addi a1, a1, 1; addi a2, a2, 1)
  TEST_CASE(30, t0, 0x0, lbu t0, 0(a1); addi a1, a1, 1; addi a2, a2, 1)

  TEST_PASSFAIL

RVTEST_CODE_END

  .data
RVTEST_DATA_BEGIN

res:
  .zero 40

sres:
  .zero 40

tdat:
  .quad 0x103f8ffefefff
  .quad 0x1070001000100
  .quad 0x103f8ffefefff
  .quad 0x1070001000100
  .quad 0x103f8ffefefff

mask:
  .quad 0x5555555555555555
  .quad 0x5555555555555555
  .quad 0x5555555555555555
  .quad 0x5555555555555555

RVTEST_DATA_END
