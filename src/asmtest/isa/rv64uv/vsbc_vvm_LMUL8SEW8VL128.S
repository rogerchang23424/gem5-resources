
# See LICENSE for license details.

# This file is automatically generated. Do not edit.

#*****************************************************************************
# isa/rv64uv/vsbc_vvm_LMUL8SEW8VL128.S
#-----------------------------------------------------------------------------
#
# Test vsbc.vvm instructions.
# With LMUL=8, SEW=8, VL=128
#

#include "riscv_test.h"
#include "test_macros.h"

RVTEST_RV64UV

RVTEST_CODE_BEGIN

  la a1, tdat
  la a3, sres
  la a2, tdat+8
  lbu a4, 0(a1)
  lbu a5, 0(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 0(a3)
  lbu a4, 1(a1)
  lbu a5, 1(a2)
  sub a5, a4, a5
  sb a5, 1(a3)
  lbu a4, 2(a1)
  lbu a5, 2(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 2(a3)
  lbu a4, 3(a1)
  lbu a5, 3(a2)
  sub a5, a4, a5
  sb a5, 3(a3)
  lbu a4, 4(a1)
  lbu a5, 4(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 4(a3)
  lbu a4, 5(a1)
  lbu a5, 5(a2)
  sub a5, a4, a5
  sb a5, 5(a3)
  lbu a4, 6(a1)
  lbu a5, 6(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 6(a3)
  lbu a4, 7(a1)
  lbu a5, 7(a2)
  sub a5, a4, a5
  sb a5, 7(a3)
  lbu a4, 8(a1)
  lbu a5, 8(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 8(a3)
  lbu a4, 9(a1)
  lbu a5, 9(a2)
  sub a5, a4, a5
  sb a5, 9(a3)
  lbu a4, 10(a1)
  lbu a5, 10(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 10(a3)
  lbu a4, 11(a1)
  lbu a5, 11(a2)
  sub a5, a4, a5
  sb a5, 11(a3)
  lbu a4, 12(a1)
  lbu a5, 12(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 12(a3)
  lbu a4, 13(a1)
  lbu a5, 13(a2)
  sub a5, a4, a5
  sb a5, 13(a3)
  lbu a4, 14(a1)
  lbu a5, 14(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 14(a3)
  lbu a4, 15(a1)
  lbu a5, 15(a2)
  sub a5, a4, a5
  sb a5, 15(a3)
  lbu a4, 16(a1)
  lbu a5, 16(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 16(a3)
  lbu a4, 17(a1)
  lbu a5, 17(a2)
  sub a5, a4, a5
  sb a5, 17(a3)
  lbu a4, 18(a1)
  lbu a5, 18(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 18(a3)
  lbu a4, 19(a1)
  lbu a5, 19(a2)
  sub a5, a4, a5
  sb a5, 19(a3)
  lbu a4, 20(a1)
  lbu a5, 20(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 20(a3)
  lbu a4, 21(a1)
  lbu a5, 21(a2)
  sub a5, a4, a5
  sb a5, 21(a3)
  lbu a4, 22(a1)
  lbu a5, 22(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 22(a3)
  lbu a4, 23(a1)
  lbu a5, 23(a2)
  sub a5, a4, a5
  sb a5, 23(a3)
  lbu a4, 24(a1)
  lbu a5, 24(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 24(a3)
  lbu a4, 25(a1)
  lbu a5, 25(a2)
  sub a5, a4, a5
  sb a5, 25(a3)
  lbu a4, 26(a1)
  lbu a5, 26(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 26(a3)
  lbu a4, 27(a1)
  lbu a5, 27(a2)
  sub a5, a4, a5
  sb a5, 27(a3)
  lbu a4, 28(a1)
  lbu a5, 28(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 28(a3)
  lbu a4, 29(a1)
  lbu a5, 29(a2)
  sub a5, a4, a5
  sb a5, 29(a3)
  lbu a4, 30(a1)
  lbu a5, 30(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 30(a3)
  lbu a4, 31(a1)
  lbu a5, 31(a2)
  sub a5, a4, a5
  sb a5, 31(a3)
  lbu a4, 32(a1)
  lbu a5, 32(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 32(a3)
  lbu a4, 33(a1)
  lbu a5, 33(a2)
  sub a5, a4, a5
  sb a5, 33(a3)
  lbu a4, 34(a1)
  lbu a5, 34(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 34(a3)
  lbu a4, 35(a1)
  lbu a5, 35(a2)
  sub a5, a4, a5
  sb a5, 35(a3)
  lbu a4, 36(a1)
  lbu a5, 36(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 36(a3)
  lbu a4, 37(a1)
  lbu a5, 37(a2)
  sub a5, a4, a5
  sb a5, 37(a3)
  lbu a4, 38(a1)
  lbu a5, 38(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 38(a3)
  lbu a4, 39(a1)
  lbu a5, 39(a2)
  sub a5, a4, a5
  sb a5, 39(a3)
  lbu a4, 40(a1)
  lbu a5, 40(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 40(a3)
  lbu a4, 41(a1)
  lbu a5, 41(a2)
  sub a5, a4, a5
  sb a5, 41(a3)
  lbu a4, 42(a1)
  lbu a5, 42(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 42(a3)
  lbu a4, 43(a1)
  lbu a5, 43(a2)
  sub a5, a4, a5
  sb a5, 43(a3)
  lbu a4, 44(a1)
  lbu a5, 44(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 44(a3)
  lbu a4, 45(a1)
  lbu a5, 45(a2)
  sub a5, a4, a5
  sb a5, 45(a3)
  lbu a4, 46(a1)
  lbu a5, 46(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 46(a3)
  lbu a4, 47(a1)
  lbu a5, 47(a2)
  sub a5, a4, a5
  sb a5, 47(a3)
  lbu a4, 48(a1)
  lbu a5, 48(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 48(a3)
  lbu a4, 49(a1)
  lbu a5, 49(a2)
  sub a5, a4, a5
  sb a5, 49(a3)
  lbu a4, 50(a1)
  lbu a5, 50(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 50(a3)
  lbu a4, 51(a1)
  lbu a5, 51(a2)
  sub a5, a4, a5
  sb a5, 51(a3)
  lbu a4, 52(a1)
  lbu a5, 52(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 52(a3)
  lbu a4, 53(a1)
  lbu a5, 53(a2)
  sub a5, a4, a5
  sb a5, 53(a3)
  lbu a4, 54(a1)
  lbu a5, 54(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 54(a3)
  lbu a4, 55(a1)
  lbu a5, 55(a2)
  sub a5, a4, a5
  sb a5, 55(a3)
  lbu a4, 56(a1)
  lbu a5, 56(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 56(a3)
  lbu a4, 57(a1)
  lbu a5, 57(a2)
  sub a5, a4, a5
  sb a5, 57(a3)
  lbu a4, 58(a1)
  lbu a5, 58(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 58(a3)
  lbu a4, 59(a1)
  lbu a5, 59(a2)
  sub a5, a4, a5
  sb a5, 59(a3)
  lbu a4, 60(a1)
  lbu a5, 60(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 60(a3)
  lbu a4, 61(a1)
  lbu a5, 61(a2)
  sub a5, a4, a5
  sb a5, 61(a3)
  lbu a4, 62(a1)
  lbu a5, 62(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 62(a3)
  lbu a4, 63(a1)
  lbu a5, 63(a2)
  sub a5, a4, a5
  sb a5, 63(a3)
  lbu a4, 64(a1)
  lbu a5, 64(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 64(a3)
  lbu a4, 65(a1)
  lbu a5, 65(a2)
  sub a5, a4, a5
  sb a5, 65(a3)
  lbu a4, 66(a1)
  lbu a5, 66(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 66(a3)
  lbu a4, 67(a1)
  lbu a5, 67(a2)
  sub a5, a4, a5
  sb a5, 67(a3)
  lbu a4, 68(a1)
  lbu a5, 68(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 68(a3)
  lbu a4, 69(a1)
  lbu a5, 69(a2)
  sub a5, a4, a5
  sb a5, 69(a3)
  lbu a4, 70(a1)
  lbu a5, 70(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 70(a3)
  lbu a4, 71(a1)
  lbu a5, 71(a2)
  sub a5, a4, a5
  sb a5, 71(a3)
  lbu a4, 72(a1)
  lbu a5, 72(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 72(a3)
  lbu a4, 73(a1)
  lbu a5, 73(a2)
  sub a5, a4, a5
  sb a5, 73(a3)
  lbu a4, 74(a1)
  lbu a5, 74(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 74(a3)
  lbu a4, 75(a1)
  lbu a5, 75(a2)
  sub a5, a4, a5
  sb a5, 75(a3)
  lbu a4, 76(a1)
  lbu a5, 76(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 76(a3)
  lbu a4, 77(a1)
  lbu a5, 77(a2)
  sub a5, a4, a5
  sb a5, 77(a3)
  lbu a4, 78(a1)
  lbu a5, 78(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 78(a3)
  lbu a4, 79(a1)
  lbu a5, 79(a2)
  sub a5, a4, a5
  sb a5, 79(a3)
  lbu a4, 80(a1)
  lbu a5, 80(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 80(a3)
  lbu a4, 81(a1)
  lbu a5, 81(a2)
  sub a5, a4, a5
  sb a5, 81(a3)
  lbu a4, 82(a1)
  lbu a5, 82(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 82(a3)
  lbu a4, 83(a1)
  lbu a5, 83(a2)
  sub a5, a4, a5
  sb a5, 83(a3)
  lbu a4, 84(a1)
  lbu a5, 84(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 84(a3)
  lbu a4, 85(a1)
  lbu a5, 85(a2)
  sub a5, a4, a5
  sb a5, 85(a3)
  lbu a4, 86(a1)
  lbu a5, 86(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 86(a3)
  lbu a4, 87(a1)
  lbu a5, 87(a2)
  sub a5, a4, a5
  sb a5, 87(a3)
  lbu a4, 88(a1)
  lbu a5, 88(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 88(a3)
  lbu a4, 89(a1)
  lbu a5, 89(a2)
  sub a5, a4, a5
  sb a5, 89(a3)
  lbu a4, 90(a1)
  lbu a5, 90(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 90(a3)
  lbu a4, 91(a1)
  lbu a5, 91(a2)
  sub a5, a4, a5
  sb a5, 91(a3)
  lbu a4, 92(a1)
  lbu a5, 92(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 92(a3)
  lbu a4, 93(a1)
  lbu a5, 93(a2)
  sub a5, a4, a5
  sb a5, 93(a3)
  lbu a4, 94(a1)
  lbu a5, 94(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 94(a3)
  lbu a4, 95(a1)
  lbu a5, 95(a2)
  sub a5, a4, a5
  sb a5, 95(a3)
  lbu a4, 96(a1)
  lbu a5, 96(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 96(a3)
  lbu a4, 97(a1)
  lbu a5, 97(a2)
  sub a5, a4, a5
  sb a5, 97(a3)
  lbu a4, 98(a1)
  lbu a5, 98(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 98(a3)
  lbu a4, 99(a1)
  lbu a5, 99(a2)
  sub a5, a4, a5
  sb a5, 99(a3)
  lbu a4, 100(a1)
  lbu a5, 100(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 100(a3)
  lbu a4, 101(a1)
  lbu a5, 101(a2)
  sub a5, a4, a5
  sb a5, 101(a3)
  lbu a4, 102(a1)
  lbu a5, 102(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 102(a3)
  lbu a4, 103(a1)
  lbu a5, 103(a2)
  sub a5, a4, a5
  sb a5, 103(a3)
  lbu a4, 104(a1)
  lbu a5, 104(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 104(a3)
  lbu a4, 105(a1)
  lbu a5, 105(a2)
  sub a5, a4, a5
  sb a5, 105(a3)
  lbu a4, 106(a1)
  lbu a5, 106(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 106(a3)
  lbu a4, 107(a1)
  lbu a5, 107(a2)
  sub a5, a4, a5
  sb a5, 107(a3)
  lbu a4, 108(a1)
  lbu a5, 108(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 108(a3)
  lbu a4, 109(a1)
  lbu a5, 109(a2)
  sub a5, a4, a5
  sb a5, 109(a3)
  lbu a4, 110(a1)
  lbu a5, 110(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 110(a3)
  lbu a4, 111(a1)
  lbu a5, 111(a2)
  sub a5, a4, a5
  sb a5, 111(a3)
  lbu a4, 112(a1)
  lbu a5, 112(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 112(a3)
  lbu a4, 113(a1)
  lbu a5, 113(a2)
  sub a5, a4, a5
  sb a5, 113(a3)
  lbu a4, 114(a1)
  lbu a5, 114(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 114(a3)
  lbu a4, 115(a1)
  lbu a5, 115(a2)
  sub a5, a4, a5
  sb a5, 115(a3)
  lbu a4, 116(a1)
  lbu a5, 116(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 116(a3)
  lbu a4, 117(a1)
  lbu a5, 117(a2)
  sub a5, a4, a5
  sb a5, 117(a3)
  lbu a4, 118(a1)
  lbu a5, 118(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 118(a3)
  lbu a4, 119(a1)
  lbu a5, 119(a2)
  sub a5, a4, a5
  sb a5, 119(a3)
  lbu a4, 120(a1)
  lbu a5, 120(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 120(a3)
  lbu a4, 121(a1)
  lbu a5, 121(a2)
  sub a5, a4, a5
  sb a5, 121(a3)
  lbu a4, 122(a1)
  lbu a5, 122(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 122(a3)
  lbu a4, 123(a1)
  lbu a5, 123(a2)
  sub a5, a4, a5
  sb a5, 123(a3)
  lbu a4, 124(a1)
  lbu a5, 124(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 124(a3)
  lbu a4, 125(a1)
  lbu a5, 125(a2)
  sub a5, a4, a5
  sb a5, 125(a3)
  lbu a4, 126(a1)
  lbu a5, 126(a2)
  sub a5, a4, a5
  addi a5, a5, -1
  sb a5, 126(a3)
  lbu a4, 127(a1)
  lbu a5, 127(a2)
  sub a5, a4, a5
  sb a5, 127(a3)


  li t0, -1
  vsetvli t1, t0, e8,m8,ta,ma
  la a2, tdat
  vle8.v v16, (a2)
  vle8.v v8, (a2)
  la a2, tdat+8
  vle8.v v24, (a2)

  
  li t0, -1
  vsetvli t1, t0, e8,m1,ta,ma
  la a3, mask
  vle8.v v0, (a3)

  li t0, 128
  vsetvli t1, t0, e8,m8,ta,ma
  vsbc.vvm v8, v16, v24, v0

  li t0, -1
  vsetvli t1, t0, e8,m8,ta,ma
  la a1, res
  vse8.v v8, (a1)
  la a2, sres

  TEST_CASE_REG(3, t0, t1, ld t0, 0(a1); ld t1, 0(a2); addi a1, a1, 8; addi a2, a2, 8)
  TEST_CASE_REG(4, t0, t1, ld t0, 0(a1); ld t1, 0(a2); addi a1, a1, 8; addi a2, a2, 8)
  TEST_CASE_REG(5, t0, t1, ld t0, 0(a1); ld t1, 0(a2); addi a1, a1, 8; addi a2, a2, 8)
  TEST_CASE_REG(6, t0, t1, ld t0, 0(a1); ld t1, 0(a2); addi a1, a1, 8; addi a2, a2, 8)
  TEST_CASE_REG(7, t0, t1, ld t0, 0(a1); ld t1, 0(a2); addi a1, a1, 8; addi a2, a2, 8)
  TEST_CASE_REG(8, t0, t1, ld t0, 0(a1); ld t1, 0(a2); addi a1, a1, 8; addi a2, a2, 8)
  TEST_CASE_REG(9, t0, t1, ld t0, 0(a1); ld t1, 0(a2); addi a1, a1, 8; addi a2, a2, 8)
  TEST_CASE_REG(10, t0, t1, ld t0, 0(a1); ld t1, 0(a2); addi a1, a1, 8; addi a2, a2, 8)
  TEST_CASE_REG(11, t0, t1, ld t0, 0(a1); ld t1, 0(a2); addi a1, a1, 8; addi a2, a2, 8)
  TEST_CASE_REG(12, t0, t1, ld t0, 0(a1); ld t1, 0(a2); addi a1, a1, 8; addi a2, a2, 8)
  TEST_CASE_REG(13, t0, t1, ld t0, 0(a1); ld t1, 0(a2); addi a1, a1, 8; addi a2, a2, 8)
  TEST_CASE_REG(14, t0, t1, ld t0, 0(a1); ld t1, 0(a2); addi a1, a1, 8; addi a2, a2, 8)
  TEST_CASE_REG(15, t0, t1, ld t0, 0(a1); ld t1, 0(a2); addi a1, a1, 8; addi a2, a2, 8)
  TEST_CASE_REG(16, t0, t1, ld t0, 0(a1); ld t1, 0(a2); addi a1, a1, 8; addi a2, a2, 8)
  TEST_CASE_REG(17, t0, t1, ld t0, 0(a1); ld t1, 0(a2); addi a1, a1, 8; addi a2, a2, 8)
  TEST_CASE_REG(18, t0, t1, ld t0, 0(a1); ld t1, 0(a2); addi a1, a1, 8; addi a2, a2, 8)



  li t0, -1
  vsetvli t1, t0, e8,m8,ta,ma
  la a2, tdat
  vle8.v v16, (a2)
  vle8.v v8, (a2)
  la a2, tdat+8
  vle8.v v24, (a2)

  
  li t0, -1
  vsetvli t1, t0, e8,m1,ta,ma
  la a3, mask
  vle8.v v0, (a3)

  li t0, 128
  vsetvli t1, t0, e8,m8,tu,ma
  vsbc.vvm v8, v16, v24, v0

  li t0, -1
  vsetvli t1, t0, e8,m8,ta,ma
  la a1, res
  vse8.v v8, (a1)
  la a2, sres

  TEST_CASE_REG(19, t0, t1, ld t0, 0(a1); ld t1, 0(a2); addi a1, a1, 8; addi a2, a2, 8)
  TEST_CASE_REG(20, t0, t1, ld t0, 0(a1); ld t1, 0(a2); addi a1, a1, 8; addi a2, a2, 8)
  TEST_CASE_REG(21, t0, t1, ld t0, 0(a1); ld t1, 0(a2); addi a1, a1, 8; addi a2, a2, 8)
  TEST_CASE_REG(22, t0, t1, ld t0, 0(a1); ld t1, 0(a2); addi a1, a1, 8; addi a2, a2, 8)
  TEST_CASE_REG(23, t0, t1, ld t0, 0(a1); ld t1, 0(a2); addi a1, a1, 8; addi a2, a2, 8)
  TEST_CASE_REG(24, t0, t1, ld t0, 0(a1); ld t1, 0(a2); addi a1, a1, 8; addi a2, a2, 8)
  TEST_CASE_REG(25, t0, t1, ld t0, 0(a1); ld t1, 0(a2); addi a1, a1, 8; addi a2, a2, 8)
  TEST_CASE_REG(26, t0, t1, ld t0, 0(a1); ld t1, 0(a2); addi a1, a1, 8; addi a2, a2, 8)
  TEST_CASE_REG(27, t0, t1, ld t0, 0(a1); ld t1, 0(a2); addi a1, a1, 8; addi a2, a2, 8)
  TEST_CASE_REG(28, t0, t1, ld t0, 0(a1); ld t1, 0(a2); addi a1, a1, 8; addi a2, a2, 8)
  TEST_CASE_REG(29, t0, t1, ld t0, 0(a1); ld t1, 0(a2); addi a1, a1, 8; addi a2, a2, 8)
  TEST_CASE_REG(30, t0, t1, ld t0, 0(a1); ld t1, 0(a2); addi a1, a1, 8; addi a2, a2, 8)
  TEST_CASE_REG(31, t0, t1, ld t0, 0(a1); ld t1, 0(a2); addi a1, a1, 8; addi a2, a2, 8)
  TEST_CASE_REG(32, t0, t1, ld t0, 0(a1); ld t1, 0(a2); addi a1, a1, 8; addi a2, a2, 8)
  TEST_CASE_REG(33, t0, t1, ld t0, 0(a1); ld t1, 0(a2); addi a1, a1, 8; addi a2, a2, 8)
  TEST_CASE_REG(34, t0, t1, ld t0, 0(a1); ld t1, 0(a2); addi a1, a1, 8; addi a2, a2, 8)



  TEST_PASSFAIL

RVTEST_CODE_END

  .data
RVTEST_DATA_BEGIN

res:
  .zero 264

sres:
  .zero 264

tdat:
  .quad 0x103f8ffefefff
  .quad 0x1070001000100
  .quad 0x103f8ffefefff
  .quad 0x1070001000100
  .quad 0x103f8ffefefff
  .quad 0x1070001000100
  .quad 0x103f8ffefefff
  .quad 0x1070001000100
  .quad 0x103f8ffefefff
  .quad 0x1070001000100
  .quad 0x103f8ffefefff
  .quad 0x1070001000100
  .quad 0x103f8ffefefff
  .quad 0x1070001000100
  .quad 0x103f8ffefefff
  .quad 0x1070001000100
  .quad 0x103f8ffefefff
  .quad 0x1070001000100
  .quad 0x103f8ffefefff
  .quad 0x1070001000100
  .quad 0x103f8ffefefff
  .quad 0x1070001000100
  .quad 0x103f8ffefefff
  .quad 0x1070001000100
  .quad 0x103f8ffefefff
  .quad 0x1070001000100
  .quad 0x103f8ffefefff
  .quad 0x1070001000100
  .quad 0x103f8ffefefff
  .quad 0x1070001000100
  .quad 0x103f8ffefefff
  .quad 0x1070001000100
  .quad 0x103f8ffefefff

mask:
  .quad 0x5555555555555555
  .quad 0x5555555555555555
  .quad 0x5555555555555555
  .quad 0x5555555555555555

RVTEST_DATA_END
